---
title: "Tutoriel Samara"
author: "Florian Larue & Grégory Beurier & Michael Dingkuhn"
date: "2023-06-20"
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

# Installation du package samara

Le modèle Samara existe sous deux formes, une application (QT) et un package R.

Tout d'abord, installez le package samara, disponible sur github 
à l'adresse suivante :

https://github.com/GBeurier/Samara_Tutorial

Vérifiez bien la version de R installé sur votre machine afin de récupérer
la bonne version du package samara.
Le fichier récupéré est un dossier compressé qu'il est possible d'installer 
directement depuis RStudio. Dans la fenêtre en bas à droite, dans l'onglet 
"packages", cliquez sur "install". Dans la fenêtre qui vient d'apparaitre,
sélectionnez "Package Archive File (.zip; .tar.gz)" dans la première liste 
déroulante. Sélectionnez le dossier que vous venez de télécharger sur github et
cliquez ensuite sur "installer".

Si tout s'est bien déroulé, le package samara peut être chargé de la façon 
suivante :

```{r}
library(samara)
```

# Fonctions de base du package

Le package samara est un interfaçage entre le langage de programmation R 
et le modèle Samara à travers des fonctions de base permettant de 
communiquer avec le modèle (et des simulations).

## 1. Données d'entrée

La première étape consiste à importer les données d'entrée du modèle. Samara
attend en entrée deux dataframes :

* Un dataframe de données météo : date, température et humidité relative
(min, max, moyenne), précipitations, vent, rayonnement, ensoleillement, 
evapotranspiration de référence. Les variables sont en colonnes et chaque ligne
est une date.
* Un dataframe avec les paramètres : espèce, variétaux, sol et 
d'itinéraire technique. Les paramètres sont en colonnes et la valeur sur la 
première ligne.

Pour comparer les simulations avec des observations, nous allons également
charger un dataframe avec des mesures faites au champ.

```{r}

PATH_TO_FOLDER <- "Data/"

weather <- read.csv(paste0(PATH_TO_FOLDER, "weather.csv"), sep=";")
param <- read.csv(paste0(PATH_TO_FOLDER, "param.csv"), sep=";")
obs <- read.csv(paste0(PATH_TO_FOLDER, "obs.csv"), sep=";")

```


```{r}

# Les données météo
head(weather)

# Les paramètres
head(param[,1:10])

# (Optionnel) Les observations
head(obs)

```

## 2. Initiation d'une simulation

La seconde étape consiste à initialiser une simulation. Cette opération va
créer un objet simulation qu'il sera ensuite possible de lancer pour récupérer
les résultats, ou de le modifier (par exemple pour tester d'autres valeurs de
paramètres). L'initialisation dans samara se fait de la façon suivante :

```{r}

samara::init_sim_idx_simple(1, param, weather)

```

La fonction d'initialisation prend donc en argument les données d'entrées 
précédemment importées (paramètres, météos) ainsi qu'un entier permettant 
d'identifier une simulation (plusieurs simulations peuvent être initiées en 
même temps). 


## 3. Lancer une simulation

Lorsque la simulation a été initiée, elle peut être lancée à l'aide de la 
fonction run_sim_idx en précisant l'identifiant de la simulation à lancer :

```{r}

res <- samara::run_sim_idx(1)
head(res[,1:5])

```

La fonction run_sim_idx renvoie un dataframe avec les résultats de simulations.

Il est possible de modifier une simulation initiée à l'aide de la fonction
update_sim_idx qui prend en argument l'identifiant d'une simulation ainsi que 
les valeurs et les noms des paramètres à modifier :

```{r}

# on lance une simulation en modifiant le paramètre phyllo_init à la valeur 35
samara::update_sim_idx(1, 40, c("phyllo"))
res <- samara::run_sim_idx(1)
head(res[,1:5])

```

Ke dataframe retourné par la fonction run_sim_idx() est
l'ensemble de la simulation (toutes les variables simulées pour l'ensemble des 
dates du premier jour de simulation au dernier jour).

Il est alors possible de réduire les résultats pour n'afficher que les résultats
correspondants aux dates et traits du dataframe d'observations :

```{r}

res <- samara::rcpp_reduceResults(res, obs)
head(res)

```

A noter que si le fichier observations contient des colonnes (et/ou dates) qui
ne sont pas présentes dans le dataframe de résultats de simulation, il est aussi
possible de les retirer automatiquement à l'aide de la fonction suivante :

```{r}

obs$test <- 1234 # ajout d'une variable absente de res
head(obs)

obs <- samara::rcpp_reduceVobs(obs, res)
head(obs)

```


# Exemple d'utilisation : estimation de paramètres

Dans ce tutoriel on va utiliser le package samara pour 
l'estimation de paramètres. Avant de commencer, chargement des packages et 
lecture des données :

```{r, message=FALSE}

# au besoin installez DEoptim (algorithme d'optimisation)
# install.packages("DEoptim")
library(DEoptim)

# lire les données d'estimation
estimParam <- read.csv(paste0(PATH_TO_FOLDER,"estimparam.csv"), sep=";")
bounds <- as.data.frame(estimParam[,c(2,3)]) # récupérer les bornes inf et sup
paramNames <- as.vector(estimParam[,1]) # récupérer les noms des paramètres
paramNames <- tolower(paramNames)
head(estimParam)

```

L'estimation de paramètres consiste à trouver les valeurs de quelques paramètres
génotypiques qui minimisent les écarts entre les simulations et les observations.
L'algorithme d'optimisation (ici DEoptim) fournit à chaque itération un set de
paramètres à tester (valeurs entre les bornes définies dans "bounds",
pour les paramètres définis dans "paramNames")

## 1. Mise en place de l'optimisation

La première étape consiste donc à mettre en place l'optimisation :

```{r}

# Définir une fonction qui calcule l'écart entre simulation et observations
error_fn <- function(obs, sim) {
  nmse <- ((obs - sim)/obs)^2
  nrmse <- sum((colSums(nmse, na.rm=T))/(colSums(!is.na(nmse))),na.rm=T)
  return(nrmse)
}

# Définir la fonction de coût qui reçoit des valeurs de paramètres en entrée
# et retourne l'erreur associé 
isInit <- FALSE # permet de vérifier si une simulation est déjà initiée
fitness_fn <- function(p) {
  if(!isInit) { # si la simulation n'est pas encore initiée, l'initier
    samara::init_sim_idx_simple(1, param, weather)
    isInit <- TRUE
  }
  
  # Modifier les paramètres et lancer la simulation
  samara::update_sim_idx(1, p, paramNames)
  sim <- samara::run_sim_idx(1)
  # réduire le dataframe de résultats pour correspondre aux dimensions de obs
  sim <- samara::rcpp_reduceResults(sim, obs)
  # calculer l'erreur
  error <- error_fn(obs, sim)
  # retourner l'erreur
  return(error)
}

```

## 2. Lancer l'optimisation

L'étape suivante est de lancer l'optimisation à l'aide de la fonction DEoptim :

```{r}

res <- DEoptim(fn = fitness_fn, lower = bounds[,1], upper = bounds[,2], 
               control = DEoptim.control(itermax = 20))

```

Ici pour l'exemple on ne lance que 20 itérations (itermax = 20), en réalité il 
faut un nombre bien plus important d'itérations pour trouver un optimum (dans
les travaux récents avec Samara, plutôt autour de 2500-5000 itérations).

DEoptim renvoie une liste avec plusieurs éléments. D'abord l'élément "optim" qui
résume la valeur de chaque paramètre trouvé, la plus petite erreur trouvée, le
nombre d'évaluations (à chaque itération plusieurs évaluations ont lieu) et le
nombre d'itérations avant l'arrêt de l'algorithme. A noter que d'autres critères
d'arrêts sont disponibles et que le nombre d'itération peut donc être plus 
faible que le paramètre itermax.

```{r}

head(res$optim)

```

Ensuite l'élément "member" qui résume dans le sous-élément bestmemit le meilleur
candidat à chaque itération et dans le sous-élément pop les valeurs de paramètres
pour chaque évaluation.

```{r}

head(res$member$bestmemit)

```

## 3. Récuperer les résultats de l'estimation

Les résultats de l'estimation sont donc stockés dans la variable res, il suffit
alors de remplacer les nouvelles valeurs de paramètres dans le dataframe d'origine
et de relancer la simulation pour obtenir les résultats de simulation de l'optimum
trouvé par l'algorithme. 

```{r}

# au besoin installer le package ggplot2
# install.packages(ggplot2)

library(ggplot2)

finalParam <- data.frame(Param = paramNames, Values = res$optim$bestmem,
                         Lower = bounds[,1], Upper = bounds[,2])
head(finalParam)

# remplacer dans le dataframe param original les nouvelles valeurs de paramètres
param[1,match(paramNames, colnames(param))] <- res$optim$bestmem

# relancer la simulation avec les nouvelles valeurs de paramètres
samara::init_sim_idx_simple(2, param, weather)
finalSim <- samara::run_sim_idx(2)
finalSim$day <- as.numeric(row.names(finalSim))

# tracer un graphe avec la simulation d'un trait (ici la biomasse aérienne)
# et ajouter les points d'observations 
plt <- ggplot(finalSim, aes(x = day, y=DryMatAboveGroundPop)) + geom_line() +
  geom_point(data = obs, aes(x = nbjas, y=drymatabovegroundpop))
print(plt)

```

De façon similaire, on peut également regarder l'évolution de l'estimation
en traçant le graphe du meilleur candidat à chaque itération, pour l'exemple
on regarde ici un autre trait simulé/mesuré (pht = la hauteur de la plante) :

```{r}

# récuperer les meilleurs candidats (uniques) sur l'ensemble des itérations
bestmems <- unique(res$member$bestmemit)

# construire un dataframe de résultats pour l'ensemble de ces candidats
bestRes <- data.frame()
for(i in 1:nrow(bestmems)) {
  param[1,match(paramNames, colnames(param))] <- bestmems[i,]
  
  samara::init_sim_idx_simple(2+i, param, weather)
  bestSim <- samara::run_sim_idx(2+i)  
  bestRes <- rbind(bestRes, data.frame(das = as.numeric(row.names(bestSim)),
                                       pht = bestSim$PlantHeight, it = i))
}

# tracer le graphe
plt2 <- ggplot(bestRes, aes(x=das, y=pht, col=as.factor(it))) +
  geom_line() + geom_point(data = obs, aes(x = nbjas, y=plantheight), inherit.aes = F)
print(plt2)

```

La dernière itération n'est pas spécialement le meilleur candidat pour le trait
qu'on regarde ici (pht). Ce qui amène à un point important de l'estimation de 
paramètres présenté dans ce tutoriel : l'erreur est calculée sur un ensemble
de traits phénotypiques (une RMSE normalisée, sur toutes les dates de mesures 
et tous les traits dans le fichier vobs.txt). De fait, si un candidat a une 
erreur globale plus faible, il sera sélectionné même si cela implique d'augmenter
l'erreur sur un trait donné. Une solution envisageable est de faire de 
l'optimisation multi-critère. Cela dépasse le cadre de ce tutoriel mais pour les
personnes intéressées, voir par exemple :

Tamaki, H., Kita, H., & Kobayashi, S. (1996, May). Multi-objective optimization by genetic algorithms: A review. In Proceedings of IEEE international conference on evolutionary computation (pp. 517-522). IEEE

Konak, A., Coit, D. W., & Smith, A. E. (2006). Multi-objective optimization using genetic algorithms: A tutorial. Reliability engineering & system safety, 91(9), 992-1007.


D'autres pistes d'améliorations peuvent être explorées avant de passer à 
l'optimisation multi-critère : en modifiant la fonction de calcul de l'erreur
pour mettre du poids sur l'un ou l'autre trait prioritaire par exemple.

Lorsque les paramètres pour un génotype donné ont été estimés, il est alors 
possible d'utiliser le modèle Samara pour d'autres analyses tels que 
présentés pendant le séminaire.
